{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 Design Tradeoffs in Digital Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author: @BrianQJN qujianning0401@163.com brian.qu@mail.utoronto.ca \n",
    "##### Date: 2023-10-14 \n",
    "##### Version: 1.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1 Chroma up-sampling, YUV pixel manipulation, YUV-RGB CSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Read the YUV 4:2:0 video sequence(s), and upscale it to 4:4:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_yuv420_video(yuv_file_path: str, width: int, height: int, num_frames: int) -> (list, list, list):\n",
    "    \"\"\"\n",
    "    Read YUV420 video file, and return pixel data of the three components Y, U, and V.\n",
    "    Args:\n",
    "        yuv_file_path (str): Path of the YUV420 video file.\n",
    "        width (int): Width of the video.\n",
    "        height (int): Height of the video.\n",
    "        num_frames (int): Number of frames to read.\n",
    "    Returns:\n",
    "        y_data (list): A list of pixel data for the brightness (Y) component\n",
    "        cb_data (list): The list of pixel data for the chroma (Cb) component\n",
    "        cr_data (list): The list of pixel data for the chroma (Cr) component\n",
    "    \"\"\"\n",
    "    # initialize the three lists of pixel data\n",
    "    y_data = []\n",
    "    cb_data = []\n",
    "    cr_data = []\n",
    "\n",
    "    with open(yuv_file_path, 'rb') as file:\n",
    "        for _ in range(num_frames):\n",
    "            # read the Y component\n",
    "            y_frame = np.fromfile(file, dtype=np.uint8, count=width * height).reshape((height, width))\n",
    "            y_data.append(y_frame)\n",
    "\n",
    "            # read the U component\n",
    "            cb_frame = np.fromfile(file, dtype=np.uint8, count=(width // 2) * (height // 2)).reshape((height // 2, width // 2))\n",
    "            cb_data.append(cb_frame)\n",
    "\n",
    "            # read the V component\n",
    "            cr_frame = np.fromfile(file, dtype=np.uint8, count=(width // 2) * (height // 2)).reshape((height // 2, width // 2))\n",
    "            cr_data.append(cr_frame)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return y_data, cb_data, cr_data\n",
    "\n",
    "\n",
    "def upscale_420_to_444(y_data: list, cb_data: list, cr_data: list) -> list:\n",
    "    \"\"\"\n",
    "    Scale 4:2:0 pixel data to 4:4:4 pixel data.\n",
    "    Args:\n",
    "        y_data (list): A list of pixel data for the brightness (Y) component\n",
    "        cb_data (list): The list of pixel data for the chroma (Cb) component\n",
    "        cr_data (list): The list of pixel data for the chroma (Cr) component\n",
    "    Returns:\n",
    "        yuv444_data (list): A list of pixel data for the YUV444 video.\n",
    "    \"\"\"\n",
    "    # initialize the list of pixel data for the YUV444 video\n",
    "    yuv444_data = []\n",
    "\n",
    "    for y_frame, cb_frame, cr_frame in zip(y_data, cb_data, cr_data):\n",
    "        # upscale the U(cb) and V(cr) component, copy to fill\n",
    "        cb_upsampled = np.repeat(np.repeat(cb_frame, 2, axis=0), 2, axis=1)\n",
    "        cr_upsampled = np.repeat(np.repeat(cr_frame, 2, axis=0), 2, axis=1)\n",
    "\n",
    "        # combine the Y, U, and V component\n",
    "        yuv444_frame = np.dstack((y_frame, cb_upsampled, cr_upsampled))\n",
    "        yuv444_data.append(yuv444_frame)\n",
    "\n",
    "    return yuv444_data\n",
    "\n",
    "\n",
    "def save_yuv444_video(yuv444_data: list, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Save the YUV444 video to a file.\n",
    "    Args:\n",
    "        yuv444_data (list): A list of pixel data for the YUV444 video.\n",
    "        output_file (str): Path of the output file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'wb') as file:\n",
    "        for frame in yuv444_data:\n",
    "            frame.tofile(file)\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"videos/420/foreman_cif.yuv\"\n",
    "output_file = \"videos/444/foreman_cif.yuv\"\n",
    "width = 352\n",
    "height = 288\n",
    "num_frames = 300\n",
    "\n",
    "# read the YUV420 video\n",
    "y_data, u_data, v_data = read_yuv420_video(input_file, width, height, num_frames)\n",
    "\n",
    "# upscale the YUV420 video to YUV444\n",
    "yuv444_data = upscale_420_to_444(y_data, u_data, v_data)\n",
    "\n",
    "# save the YUV444 video\n",
    "save_yuv444_video(yuv444_data, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Convert the YUV 4:4:4 video sequence(s) to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def yuv444_to_rgb(yuv444_data: list, csc_matrix: list) -> list:\n",
    "    \"\"\"\n",
    "    Convert YUV 4:4:4 pixel data to RGB pixel data.\n",
    "    Args:\n",
    "        yuv444_data (list): 444yuv pixel data list\n",
    "        csc_matrix (list): convert matrix\n",
    "    Returns:\n",
    "        rgb_data (list): RGB pixel data list\n",
    "    \"\"\"\n",
    "    rgb_data = []\n",
    "\n",
    "    for yuv_frame in yuv444_data:\n",
    "        # convert 444yuv pixel data to matrix\n",
    "        yuv_matrix = np.array(yuv_frame).reshape(-1, 3)\n",
    "\n",
    "        # convert 444yuv pixel data to 444rgb pixel data\n",
    "        rgb_matrix = np.dot(yuv_matrix - [16, 128, 128], np.array(csc_matrix).reshape(3, 3).T)\n",
    "\n",
    "        # convert 444rgb pixel data to 444rgb frame data\n",
    "        rgb_frame = np.clip(rgb_matrix, 0, 255).astype(np.uint8).reshape(yuv_frame.shape)\n",
    "\n",
    "        # add rgb frame data to rgb data list\n",
    "        rgb_data.append(rgb_frame)\n",
    "\n",
    "    return rgb_data\n",
    "\n",
    "def save_rgb_images(rgb_data: list, output_prefix: str, stop_frame=300) -> None:\n",
    "    \"\"\"\n",
    "    Convert RGB pixel data to RGB images and save them as .png files.\n",
    "    Args:\n",
    "        rgb_data (list): rgb pixel data list\n",
    "        output_prefix (str): png file prefix\n",
    "    \"\"\"\n",
    "    for i, rgb_frame in enumerate(rgb_data):\n",
    "        # create pillow image object\n",
    "        img = Image.fromarray(rgb_frame)\n",
    "\n",
    "        # save image\n",
    "        img.save(f\"images/{output_prefix}_{i:03d}.png\")\n",
    "        if i == stop_frame:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc_matrix = [1.164, 0, 1.596, 1.164, -0.392, -0.813, 1.164, 2.017, 0]\n",
    "\n",
    "rgb_data = yuv444_to_rgb(yuv444_data, csc_matrix)\n",
    "\n",
    "save_rgb_images(rgb_data, \"images\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E2 Basic block-based operations on video content and quality assessment metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a Read the Y-component of 4:2:0 video sequences, and dump it into corresponding Y-only files of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_y_component(yuv420_data: list) -> list:\n",
    "    \"\"\"\n",
    "    Extract the Y component from the YUV420 pixel data.\n",
    "    Args:\n",
    "        yuv420_data (list): A list of pixel data for the YUV420 video.\n",
    "    Returns:\n",
    "        y_data (list): A list of pixel data for the brightness (Y) component\n",
    "    \"\"\"\n",
    "    y_data = []\n",
    "\n",
    "    for yuv_frame in yuv420_data:\n",
    "        # extract the Y component\n",
    "        y_frame = yuv_frame[:, :, 0]\n",
    "        y_data.append(y_frame)\n",
    "\n",
    "    return y_data\n",
    "\n",
    "\n",
    "def save_y_only_files(y_data: list, output_prefix: str, stop_frames=300) -> None:    \n",
    "    \"\"\"\n",
    "    Save the Y component to files.\n",
    "    Args:\n",
    "        y_data (list): A list of pixel data for the brightness (Y) component\n",
    "        output_prefix (str): Path of the output file.\n",
    "        stop_frames (int): Number of frames to save.\n",
    "    \"\"\"\n",
    "    for i, y_frame in enumerate(y_data):\n",
    "        # save the Y component to files\n",
    "        output_file = f\"y_only_files/{output_prefix}_{i:03d}.y\"\n",
    "\n",
    "        y_frame.tofile(output_file)\n",
    "\n",
    "        if i == stop_frames:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = read_yuv420_video(input_file, width, height, num_frames)[0]\n",
    "save_y_only_files(y_data, \"foreman_cif\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b Read every Y-only file, and apply to it the following operation(s):\n",
    "i. Split each frame into (ùëñ √ó ùëñ) blocks (where (ùëñ) takes the values 2, 8, and 64)\n",
    "ii. Use ‚Äúpadding‚Äù if the width and/or height of the frame is not divisible by (ùëñ). Pad with gray (128).\n",
    "If padding is necessary, padding pixels should be placed at the right and/or bottom of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_y_only_file(file_path: str, width: int, height: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Read the Y component from a file. \n",
    "    Args:\n",
    "        file_path (str): Path of the file.\n",
    "        width (int): Width of the video.\n",
    "        height (int): Height of the video.√•\n",
    "    Returns:\n",
    "        y_frame (np.array): A numpy array of pixel data for the brightness (Y) component\n",
    "    \"\"\"   \n",
    "    with open(file_path, 'rb') as file:\n",
    "        # read the Y component\n",
    "        y_frame = np.fromfile(file, dtype=np.uint8, count=width * height).reshape((height, width))\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return y_frame\n",
    "\n",
    "def split_frame_into_blocks(y_frame: np.array, block_size: int) -> list:\n",
    "    \"\"\"\n",
    "    Split a frame into blocks.\n",
    "    Args:\n",
    "        y_frame (np.array): A numpy array of pixel data for the brightness (Y) component\n",
    "        block_size (int): Size of the block.\n",
    "    Returns:\n",
    "        blocks (list): A list of blocks.\n",
    "    \"\"\"\n",
    "    height, width = y_frame.shape\n",
    "    padding_needed = False\n",
    "\n",
    "    # calculate the width and height to see if padding is needed\n",
    "    if width % block_size != 0:\n",
    "        padding_width = block_size - (width % block_size)\n",
    "        padding_needed = True\n",
    "    else:\n",
    "        padding_width = 0\n",
    "\n",
    "    if height % block_size != 0:\n",
    "        padding_height = block_size - (height % block_size)\n",
    "        padding_needed = True\n",
    "    else:\n",
    "        padding_height = 0\n",
    "\n",
    "    # if padding is needed, pad the frame with gray(128)\n",
    "    if padding_needed:\n",
    "        y_frame = np.pad(y_frame, ((0, padding_height), (0, padding_width)), 'constant', constant_values=128)\n",
    "\n",
    "    # split the frame into blocks\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, height, block_size):\n",
    "        for j in range(0, width, block_size):\n",
    "            block = y_frame[i:i + block_size, j:j + block_size]\n",
    "            blocks.append(block)\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks: 1584\n"
     ]
    }
   ],
   "source": [
    "y_frame = read_y_only_file(\"y_only_files/foreman_cif_000.y\", 352, 288)\n",
    "blocks = split_frame_into_blocks(y_frame, 8)\n",
    "print(f\"Number of blocks: {len(blocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.c Calculate the average* of the sample values within each (ùëñ √ó ùëñ) block *Use efficient rounded division by (ùëñ √ó ùëñ) while calculating the approximated average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_approximate_average(block: np.array) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the approximate average value of a block.\n",
    "    Args:\n",
    "        block (np.array): A numpy array of pixel data for a block.\n",
    "    Returns:\n",
    "        avg (int): The approximate average value of the block.\n",
    "    \"\"\"\n",
    "    avg = np.sum(block) // block.size\n",
    "    return avg\n",
    "\n",
    "def calculate_average_for_blocks(blocks: list) -> list:\n",
    "    \"\"\"\n",
    "    Calculate the average value for each block.\n",
    "    Args:\n",
    "        blocks (list): A list of blocks.\n",
    "    Returns:\n",
    "        avgs (list): A list of average values for the blocks.\n",
    "    \"\"\"\n",
    "    avgs = []\n",
    "\n",
    "    for block in blocks:\n",
    "        avg = calculate_approximate_average(block)\n",
    "        avgs.append(avg)\n",
    "    \n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 2.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1: 156.0\n",
      "Block 2: 200.0\n",
      "Block 3: 200.0\n",
      "Block 4: 193.0\n",
      "Block 5: 199.0\n",
      "Block 6: 211.0\n",
      "Block 7: 224.0\n",
      "Block 8: 220.0\n",
      "Block 9: 194.0\n",
      "Block 10: 188.0\n"
     ]
    }
   ],
   "source": [
    "avgs = calculate_average_for_blocks(blocks)\n",
    "\n",
    "for i, avg in enumerate(avgs):\n",
    "    print(f\"Block {i+1}: {avg}\")\n",
    "    if i == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.d Replace every (ùëñ √ó ùëñ) block with another (ùëñ √ó ùëñ) block of identical elements of this average value to generate Y-only-block-averaged file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def replace_block_with_average(block: np.array, avg: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Replace a block with its average value.\n",
    "    Args:\n",
    "        block (np.array): A numpy array of pixel data for a block.\n",
    "        avg (int): The average value of the block.\n",
    "    Returns:\n",
    "        replaced_block (np.array): A numpy array of pixel data for a block.\n",
    "    \"\"\"\n",
    "    replaced_block = np.full_like(block, avg)\n",
    "    return replaced_block\n",
    "\n",
    "def replace_blocks_with_average(blocks: list, avgs: list) -> list:\n",
    "    \"\"\"\n",
    "    Replace blocks with their average values.\n",
    "    Args:\n",
    "        blocks (list): A list of blocks.\n",
    "        avgs (list): A list of average values for the blocks.\n",
    "    Returns:\n",
    "        replaced_blocks (list): A list of blocks.\n",
    "    \"\"\"\n",
    "    replaced_blocks = []\n",
    "\n",
    "    for block, avg in zip(blocks, avgs):\n",
    "        replaced_block = replace_block_with_average(block, avg)\n",
    "        replaced_blocks.append(replaced_block)\n",
    "    \n",
    "    return replaced_blocks\n",
    "\n",
    "def save_y_only_averaged_file(output_file_path: str, y_avg_only_frame: np.array) -> None:\n",
    "    \"\"\"\n",
    "    Save y only averaged file.\n",
    "    Args:\n",
    "        y_avg_only_frame (np.array): A numpy array of pixel data for the brightness (Y) component\n",
    "        output_file_path (str): Path of the output file.\n",
    "    \"\"\"\n",
    "    with open(output_file_path, 'wb') as file:\n",
    "        y_avg_only_frame.tofile(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 2.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_blocks = replace_blocks_with_average(blocks, avgs)\n",
    "\n",
    "avg_frame = np.block(replaced_blocks)\n",
    "\n",
    "output_file_path = \"y_only_avg_files/foreman_cif_000.y\"\n",
    "save_y_only_averaged_file(output_file_path, avg_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.e Subjectively compare* every original Y-only file with its corresponding Y-only-block-averaged one *In addition to the frame to frame comparison, you can use simple frame differencing (multiplied by an arbitrary factor to magnify the deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subjective_comparison(original_file_path: str, average_file_path: str, factor=1.0):\n",
    "    \"\"\"\n",
    "    Compare the original and the average file.\n",
    "    Args:\n",
    "        original_file_path (str): Path of the original file.\n",
    "        average_file_path (str): Path of the average file.\n",
    "        factor (float): The factor used to amplify the frame difference\n",
    "    Returns:\n",
    "        diff_frames (list): A list of frame differences.\n",
    "    \"\"\"\n",
    "    # read the original and the average file\n",
    "    original_frame = read_y_only_file(original_file_path, 352, 288)\n",
    "    average_frame = read_y_only_file(average_file_path, 352, 288)\n",
    "\n",
    "    # calculate the frame difference\n",
    "    diff_frame = np.abs(original_frame.astype(float) - average_frame.astype(float)) * factor\n",
    "\n",
    "    return diff_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 2.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnification_factor = 10.0\n",
    "\n",
    "diff_frames = subjective_comparison(\"y_only_files/foreman_cif_000.y\", \"y_only_avg_files/foreman_cif_000.y\", magnification_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.f Using average PSNR and SSIM among frames, compare every original Y-only file with its corresponding Y-only-block-averaged one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "def compare_y_files(original_file_path: str, average_file_path: str) -> (float, float):\n",
    "    \"\"\"\n",
    "    Compare the original and the average file using PSNR and SSIM.\n",
    "    Args:\n",
    "        original_file_path (str): Path of the original file.\n",
    "        average_file_path (str): Path of the average file.\n",
    "    Returns:\n",
    "        psnr (float): PSNR value.\n",
    "        ssim (float): SSIM value.\n",
    "    \"\"\"\n",
    "    # read the original and the average file\n",
    "    original_frame = read_y_only_file(original_file_path, 352, 288)\n",
    "    average_frame = read_y_only_file(average_file_path, 352, 288)\n",
    "\n",
    "    # calculate PSNR and SSIM\n",
    "    psnr = peak_signal_noise_ratio(original_frame, average_frame)\n",
    "    ssim = structural_similarity(original_frame, average_frame)\n",
    "\n",
    "    return psnr, ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for 2.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 11.36 dB\n",
      "SSIM: 0.12\n"
     ]
    }
   ],
   "source": [
    "psnr, ssim = compare_y_files(\"y_only_files/foreman_cif_000.y\", \"y_only_avg_files/foreman_cif_000.y\")\n",
    "\n",
    "print(f\"PSNR: {psnr:.2f} dB\")\n",
    "print(f\"SSIM: {ssim:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3 Basic Motion Estimation/Compensation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.a Repeat parts a and b of E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.b Using integer pixel full search, find the best predicted block for every (ùëñ √ó ùëñ) current block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_virtual_reference_frame(frame_shape: tuple, value=128) -> np.array:\n",
    "    \"\"\"\n",
    "    Create a virtual reference frame.\n",
    "    Args:\n",
    "        frame_shape (tuple): Shape of the frame, i.e. (height, width).\n",
    "        value (int): Value of the frame.\n",
    "    Returns:\n",
    "        virtual_reference_frame (np.array): A numpy array of pixel data for the virtual reference frame.\n",
    "    \"\"\"\n",
    "    virtual_reference_frame = np.full(frame_shape, value, dtype=np.uint8)\n",
    "    return virtual_reference_frame\n",
    "\n",
    "def integer_pixel_full_search(current_block: np.array, reference_frame: np.array, search_range: int) -> (np.array, tuple):\n",
    "    \"\"\"\n",
    "    Using integer pixel full search to find the best matching block.\n",
    "    Args:\n",
    "        current_block (np.array): A numpy array of pixel data for the current block.\n",
    "        reference_frame (np.array): A numpy array of pixel data for the reference frame.\n",
    "        search_range (int): Search range. (+/- r pixels)\n",
    "    Returns:\n",
    "        best_matching_block (np.array): A numpy array of pixel data for the best matching block.\n",
    "        motion_vector (tuple): Motion vector, i.e. (dy, dx).\n",
    "    \"\"\"\n",
    "    best_mae = float('inf')\n",
    "    best_matching_block = None\n",
    "    motion_vector = (0, 0)\n",
    "\n",
    "    height, width = current_block.shape\n",
    "\n",
    "    for dx in range(-search_range, search_range+1):\n",
    "        for dy in range(-search_range, search_range+1):\n",
    "            x_start = max(0,dx)\n",
    "            x_end = min(width, width+dx)\n",
    "            y_start = max(0,dy)\n",
    "            y_end = min(height, height+dy)\n",
    "\n",
    "            reference_block = reference_frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            if reference_block.shape == current_block.shape:\n",
    "                mae = np.abs(current_block - reference_block).mean()\n",
    "\n",
    "                if mae < best_mae:\n",
    "                    best_mae = mae\n",
    "                    best_matching_block = reference_block\n",
    "                    motion_vector = (dx, dy)\n",
    "    \n",
    "    return best_matching_block, motion_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.c Dump the x and y components of every successful MV into a text (and/or binary) file using an arbitrary format that preserves the coordinates of the block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_motion_vectors_to_file(motion_vectors: list, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save motion vectors to a file.\n",
    "    Args:\n",
    "        motion_vectors (list): A list of motion vectors.\n",
    "        file_path (str): Path of the output file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        for mv in motion_vectors:\n",
    "            x, y = mv\n",
    "            file.write(f\"{x} {y}\\n\")\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.d An (ùëñ √ó ùëñ) residual block will be generated by subtracting the predicted block from the current block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_residual_block(current_block: np.array, predicted_block: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Generate (i x i) residual block.\n",
    "    Args:\n",
    "        current_block (np.array): A numpy array of pixel data for the current block.\n",
    "        predicted_block (np.array): A numpy array of pixel data for the predicted block.\n",
    "    Returns:\n",
    "        residual_block (np.array): A numpy array of pixel data for the residual block.\n",
    "    \"\"\"\n",
    "    # check if the current block and the predicted block have the same shape\n",
    "    assert current_block.shape == predicted_block.shape\n",
    "\n",
    "    # calculate the residual block\n",
    "    residual_block = current_block - predicted_block\n",
    "\n",
    "    return residual_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.e Generate an approximated residual block by rounding every element in the (ùëñ √ó ùëñ) residual block to the nearest multiple of 2n (for ùëõ = 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def approximate_residual_block(residual_block: np.array, n: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Generate approximate residual block. Rounding each element in the residual block to the nearest multiple of 2^n.\n",
    "    Args:\n",
    "        residual_block (np.array): A numpy array of pixel data for the residual block.\n",
    "        n (int): Round to the nearest multiple of 2^n\n",
    "    Returns:\n",
    "        approximated_residual_block (np.array): A numpy array of pixel data for the approximated residual block.\n",
    "    \"\"\"\n",
    "    factor = 2 ** n\n",
    "\n",
    "    approximated_residual_block = np.round(residual_block / factor) * factor\n",
    "\n",
    "    return approximated_residual_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.f Dump the (ùëñ √ó ùëñ) approximated residual values into a text (and/or binary) file using an arbitrary format that preserves the coordinates of the block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dump_approximated_residuals_to_file():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
